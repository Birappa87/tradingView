{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "730c0468",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### update companymaster file - check ipo listing from chittorgarh \n",
    "\n",
    "### run report designer in spider and save xls for bse, nse and sme\n",
    "\n",
    "#### get marketcap from screener and save in marketcap from screener csv\n",
    "\n",
    "#### run 57 Tradingview WL for percent change and new highs - this reads the file from tradingview\n",
    "#### for 3 percent changes or more and new highs and makes a 0_tradingview_wl_yymmdd\n",
    "\n",
    "#### run 50 nse bse averages - this takes nse/bse/sme averages and creates a combined average file (input file)\n",
    "\n",
    "### run 51 combined nse bse files --- combines nse and bse files for a specific date - this combined file is used for \n",
    "#### report generation  -- this generates top 50 by value/volume for non-fno, fno and sme\n",
    "#### this also creates non_fno_wl_yymmdd\n",
    "#### this creates sme yymmdd \n",
    "\n",
    "#### run 56 delivery comparision over 2 days - this generates scrips where dely volumes are 3x of previous day\n",
    "#### this generates 0_volume_3x_wl_yymmdd\n",
    "\n",
    "#### run 53 report for multiple scrips\n",
    "#### this takes 0_tradingview_wl_yymmdd (created in 57) and generate 7-day delivery report\n",
    "#### this takes 0_volume_3x_wl_yymmdd (created in 56) and generate 7-day delivery report\n",
    "#### this takes 0_non_fno_wl_yymmdd (created in 51) and generate 7-day delivery report\n",
    "#### this takes sme yymmdd (created in 51) and generate 7-day delivery report\n",
    "#### this also reads consolidated holdings file, create 0 my_holdings and generate 7-day delivery report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4701e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "### this program reads the nse averages, bse averages, sme averages in spider/user/report folder \n",
    "### and combines them (after removing tags for trade to trade/ sm-st / z group etc)\n",
    "### and writes to nse bse averages in input folder under sql stock market data\n",
    "\n",
    "### nse bse averages is used by 53 multiple scrips to read averages and print them\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d295da95",
   "metadata": {},
   "outputs": [],
   "source": [
    "### lenovo desktop file path\n",
    "master_file_path = \"C:\\\\Users\\\\User\\\\Dropbox\\\\SQL Stock Market Data\\\\Python Code from ChatGPT\\\\Master File\\\\CompanyMaster.csv\"\n",
    "directory = \"C:\\\\Users\\\\User\\\\Dropbox\\\\SQL Stock Market Data\\\\Data Files\\\\\"  # Replace with the path to your directory\n",
    "output_path = \"C:\\\\Users\\\\User\\\\Dropbox\\\\SQL Stock Market Data\\\\Python Code from ChatGPT\\\\Output File\\\\\"\n",
    "combined_file_path = \"C:\\\\Users\\\\User\\\\Dropbox\\\\SQL Stock Market Data\\\\Delivery Price Combined Files\\\\\"\n",
    "\n",
    "column_order = ['NSE_Code','BSE_Code','Date','NSE_Delivery','BSE_Delivery']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7761cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Lenovo laptop file path\n",
    "\n",
    "\n",
    "spider_path = \"C:\\\\Spider\\\\User\\\\Report\\\\\"\n",
    "\n",
    "master_file_path = \"C:\\\\Users\\\\sarda\\\\Dropbox\\\\SQL Stock Market Data\\\\Python Code from ChatGPT\\\\Master File\\\\CompanyMaster.csv\"\n",
    "directory = \"C:\\\\Users\\\\sarda\\\\Dropbox\\\\SQL Stock Market Data\\\\Data Files\\\\\"  # Replace with the path to your directory\n",
    "output_path = \"C:\\\\Users\\\\sarda\\\\Dropbox\\\\SQL Stock Market Data\\\\Python Code from ChatGPT\\\\Output File\\\\\"\n",
    "input_path = \"C:\\\\Users\\\\sarda\\\\Dropbox\\\\SQL Stock Market Data\\\\Python Code from ChatGPT\\\\Input File\\\\\"\n",
    "combined_file_path = \"C:\\\\Users\\\\sarda\\\\Dropbox\\\\SQL Stock Market Data\\\\Delivery Price Combined Files\\\\\"\n",
    "\n",
    "# Define the new column order\n",
    "column_order = [\"Exchange\", \"Code\", \"Name\", \"Close\", \"ema5\", \"ema10\", \"ema20\", \"ema50\", \"ema200\", \"75d high\", \"75d low\"]\n",
    "\n",
    "# Define the corresponding column types\n",
    "column_types = {\"Close\": float, \"ema5\": float, \"ema10\": float, \"ema20\": float, \"ema50\": float, \"ema200\": float, \n",
    "                \"75d high\": float, \"75d low\": float}\n",
    "\n",
    "columns_to_fill = [\"Close\", \"ema5\", \"ema10\", \"ema20\", \"ema50\", \"ema200\", \"75d high\", \"75d low\"]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da18b4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "nse_avg = spider_path + \"NSE Averages.xls\"\n",
    "sme_avg = spider_path + \"SME Averages.xls\"\n",
    "bse_avg = spider_path + \"BSE Averages.xls\"\n",
    "\n",
    "input_file = input_path + \"ShortListed Stocks.xlsx\"\n",
    "\n",
    "bse_sheet = \"BSE Averages\"\n",
    "nse_sheet = \"NSE Averages\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afa163d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1b1af4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nse_avg_df = pd.read_excel(nse_avg, names=column_order, dtype=column_types)\n",
    "sme_avg_df = pd.read_excel(sme_avg, names=column_order, dtype=column_types)\n",
    "bse_avg_df = pd.read_excel(bse_avg, names=column_order, dtype=column_types)\n",
    "#input_file_df = pd.read_excel(input_file)\n",
    "\n",
    "\n",
    "nse_avg_df[columns_to_fill] = nse_avg_df[columns_to_fill].fillna(0)\n",
    "bse_avg_df[columns_to_fill] = bse_avg_df[columns_to_fill].fillna(0)\n",
    "sme_avg_df[columns_to_fill] = sme_avg_df[columns_to_fill].fillna(0)\n",
    "\n",
    "nse_sme_avg_df = pd.concat([nse_avg_df,sme_avg_df], ignore_index = True)\n",
    "\n",
    "nse_avg_df = nse_sme_avg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94e3344c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nse_avg_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "888fb3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "nse_avg_df['Name'] = nse_avg_df['Name'].str.replace('_T$',\"\",regex=True)\n",
    "nse_avg_df['Name'] = nse_avg_df['Name'].str.replace('_Z$',\"\",regex=True)\n",
    "nse_avg_df['Name'] = nse_avg_df['Name'].str.replace(' SM$',\"\",regex=True)\n",
    "nse_avg_df['Name'] = nse_avg_df['Name'].str.replace(' ST$',\"\",regex=True)\n",
    "\n",
    "\n",
    "nse_avg_df['Name'] = nse_avg_df['Name'].str.strip()\n",
    "nse_avg_df['Code'] = nse_avg_df['Code'].astype(str)\n",
    "\n",
    "bse_avg_df['Code'] = bse_avg_df['Code'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a5fe70c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been written to 'C:\\Users\\sarda\\Dropbox\\SQL Stock Market Data\\Python Code from ChatGPT\\Input File\\NSE BSE Averages.xlsx' under the sheets 'NSE Averages' and 'BSE Averages'.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Assuming nse_avg_df and bse_avg_df are your DataFrames\n",
    "\n",
    "# Replace 'NSE BSE Averages.xlsx' with the desired output file path\n",
    "averages_file = input_path + 'NSE BSE Averages.xlsx'\n",
    "\n",
    "# Use ExcelWriter to write to a new Excel file with two sheets\n",
    "with pd.ExcelWriter(averages_file, engine='openpyxl', mode='w') as writer:\n",
    "    nse_avg_df.to_excel(writer, sheet_name='NSE Averages', index=False)\n",
    "    bse_avg_df.to_excel(writer, sheet_name='BSE Averages', index=False)\n",
    "\n",
    "# Confirm the write operation\n",
    "print(f\"Data has been written to '{averages_file}' under the sheets 'NSE Averages' and 'BSE Averages'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7f3a9e",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "# code_0.ipynb\n",
    "\n",
    "import nbformat\n",
    "from nbconvert.preprocessors import ExecutePreprocessor\n",
    "\n",
    "# Load \"56 Delivery comparision over 2 days.ipynb\"\n",
    "with open('56 Delivery comparision over 2 days.ipynb', 'r') as f:\n",
    "    nb_content = nbformat.read(f, as_version=4)\n",
    "\n",
    "# Execute the notebook\n",
    "exec_preprocessor = ExecutePreprocessor(timeout=600, kernel_name='python3')\n",
    "exec_preprocessor.preprocess(nb_content, {'metadata': {'path': './'}})\n",
    "\n",
    "# Extract variables or functions from the executed notebook\n",
    "executed_code = '\\n'.join(cell['source'] for cell in nb_content.cells if cell.cell_type == 'code')\n",
    "\n",
    "# Execute the extracted code in the current notebook\n",
    "exec(executed_code)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

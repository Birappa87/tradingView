{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7fb140",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bd0fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r'C:\\Users\\sarda\\Dropbox\\Research Reports(1)'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "793746d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error decoding file ''Astral PolyTech 120525 Networth Q4 FY12 result update Passing on costs to sustain margins and counter forex volatility HOLD tgt 191.pdf': 'charmap' codec can't decode byte 0x8f in position 708: character maps to <undefined>\n",
      "Error decoding file ''Come Alive!' with avaniTVSolutions 111020 Moneycontrol.msg': 'charmap' codec can't decode byte 0x8f in position 625: character maps to <undefined>\n",
      "Error decoding file ''Cotton price volatility eroded Rs 5500 cr working capital from spinning mills 120918 MC.msg': 'charmap' codec can't decode byte 0x90 in position 1644: character maps to <undefined>\n",
      "Error decoding file ''Decision on FDI in multi-brand retail by year-end' 111019 BS.msg': 'charmap' codec can't decode byte 0x90 in position 868: character maps to <undefined>\n",
      "Error decoding file ''E-commerce is under pressure to grow due to PE 120412 DNAMoney.msg': 'charmap' codec can't decode byte 0x8f in position 2917: character maps to <undefined>\n",
      "Error decoding file ''Ethanol blending programme 120929 Care  still a distant dream'.pdf': 'charmap' codec can't decode byte 0x81 in position 1017: character maps to <undefined>\n",
      "Error decoding file ''Wockhardt 120523 Networth  Buoyant profitability leads to rich valuations BUY tgt 861.pdf': 'charmap' codec can't decode byte 0x8d in position 501: character maps to <undefined>\n",
      "Error decoding file '+ve for GSPL and GAIL - PNGRB draft amendment on tariff calculation 150713 Emkay .msg': 'charmap' codec can't decode byte 0x90 in position 620: character maps to <undefined>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sarda\\AppData\\Local\\Temp\\ipykernel_6288\\3983625373.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'File Name': file_name, 'Content': content}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error reading file '... We Are Heavily Under-Weight India  China (Arjun Divecha-GMO) high social return vs high return on capital_files': [Errno 13] Permission denied: 'C:\\\\Users\\\\sarda\\\\Dropbox\\\\Research Reports (1)\\\\... We Are Heavily Under-Weight India  China (Arjun Divecha-GMO) high social return vs high return on capital_files'\n",
      "Error decoding file '1 insulin price cap for all brands 121121 BS.docx': 'charmap' codec can't decode byte 0x81 in position 607: character maps to <undefined>\n",
      "Error decoding file '10 Annual Investor Conference 2012 120312 Icici Sec.pdf': 'charmap' codec can't decode byte 0x9d in position 296: character maps to <undefined>\n",
      "Error decoding file '10 Free and Amazing Tools ForWindows PCs ET 120402.msg': 'charmap' codec can't decode byte 0x90 in position 620: character maps to <undefined>\n",
      "Error decoding file '10 reasons why IT stocks have fallen sharply (Article in NDTV Profit) 120508.msg': 'charmap' codec can't decode byte 0x90 in position 2924: character maps to <undefined>\n",
      "Error decoding file '10 stocks for next 12 months 170321 Frwd - PI Industries-Indigo-Bicon-Alkem Lab-Dhanuka Agri-Torrent Pharma-Aurobindo Pharma -GSPL-Rallis India-HPCL.msg': 'charmap' codec can't decode byte 0x90 in position 876: character maps to <undefined>\n",
      "Error decoding file '10 stocks that destroyed Rs 6,86,559 crore 130820 ET Now.doc': 'charmap' codec can't decode byte 0x9d in position 1367: character maps to <undefined>\n",
      "Error decoding file '10 tips and tricks for your iPad 120320 DNA.msg': 'charmap' codec can't decode byte 0x81 in position 2917: character maps to <undefined>\n",
      "Error decoding file '10 ways to be happy 140226 jamesaltucher - 10 Unusual Ways to Release Oxytocin Into Your Life.msg': 'charmap' codec can't decode byte 0x81 in position 1532: character maps to <undefined>\n",
      "Error decoding file '10 Ways to Understand Buyers Psychology infographic 121122 SocialMediatoday.msg': 'charmap' codec can't decode byte 0x8f in position 623: character maps to <undefined>\n",
      "Error decoding file '100% chance of crisis worse than 2008 Jim Rogers 111110 Moneycontrol.msg': 'charmap' codec can't decode byte 0x90 in position 1644: character maps to <undefined>\n",
      "Error decoding file '101 Hand-picked Warren Buffett Quotes On Investing .msg': 'charmap' codec can't decode byte 0x8d in position 1060: character maps to <undefined>\n",
      "Error decoding file '11 stocks that have crashed anywhere between 16-60% in 5 months  110907 Moneycontrol.msg': 'charmap' codec can't decode byte 0x81 in position 2917: character maps to <undefined>\n",
      "Error decoding file '11 Timeless Tips from Buffett and Munger 130513 .msg': 'charmap' codec can't decode byte 0x9d in position 623: character maps to <undefined>\n",
      "Error decoding file '12.5% shortfall in fertiliser availability in July 110713 Moneycontrol.doc': 'charmap' codec can't decode byte 0x8e in position 1366: character maps to <undefined>\n",
      "Error decoding file '120601 Citi Takeaways from India Investor Conference  US Grwth to Accelerate.pdf': 'charmap' codec can't decode byte 0x8f in position 374: character maps to <undefined>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 15>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(full_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m---> 20\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mchardet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m         encoding \u001b[38;5;241m=\u001b[39m result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(full_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m, encoding\u001b[38;5;241m=\u001b[39mencoding) \u001b[38;5;28;01mas\u001b[39;00m file:\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\chardet\\__init__.py:41\u001b[0m, in \u001b[0;36mdetect\u001b[1;34m(byte_str)\u001b[0m\n\u001b[0;32m     39\u001b[0m         byte_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbytearray\u001b[39m(byte_str)\n\u001b[0;32m     40\u001b[0m detector \u001b[38;5;241m=\u001b[39m UniversalDetector()\n\u001b[1;32m---> 41\u001b[0m \u001b[43mdetector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbyte_str\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m detector\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\chardet\\universaldetector.py:211\u001b[0m, in \u001b[0;36mUniversalDetector.feed\u001b[1;34m(self, byte_str)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_charset_probers\u001b[38;5;241m.\u001b[39mappend(Latin1Prober())\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m prober \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_charset_probers:\n\u001b[1;32m--> 211\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mprober\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbyte_str\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m==\u001b[39m ProbingState\u001b[38;5;241m.\u001b[39mFOUND_IT:\n\u001b[0;32m    212\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresult \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m: prober\u001b[38;5;241m.\u001b[39mcharset_name,\n\u001b[0;32m    213\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconfidence\u001b[39m\u001b[38;5;124m'\u001b[39m: prober\u001b[38;5;241m.\u001b[39mget_confidence(),\n\u001b[0;32m    214\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlanguage\u001b[39m\u001b[38;5;124m'\u001b[39m: prober\u001b[38;5;241m.\u001b[39mlanguage}\n\u001b[0;32m    215\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\chardet\\charsetgroupprober.py:71\u001b[0m, in \u001b[0;36mCharSetGroupProber.feed\u001b[1;34m(self, byte_str)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m prober\u001b[38;5;241m.\u001b[39mactive:\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m---> 71\u001b[0m state \u001b[38;5;241m=\u001b[39m \u001b[43mprober\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbyte_str\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m state:\n\u001b[0;32m     73\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\chardet\\sbcharsetprober.py:118\u001b[0m, in \u001b[0;36mSingleByteCharSetProber.feed\u001b[1;34m(self, byte_str)\u001b[0m\n\u001b[0;32m    116\u001b[0m                 lm_cat \u001b[38;5;241m=\u001b[39m language_model[order][\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_order]\n\u001b[0;32m    117\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_seq_counters[lm_cat] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 118\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_order \u001b[38;5;241m=\u001b[39m order\n\u001b[0;32m    120\u001b[0m charset_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model\u001b[38;5;241m.\u001b[39mcharset_name\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m ProbingState\u001b[38;5;241m.\u001b[39mDETECTING:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import chardet\n",
    "\n",
    "# Define the directory path\n",
    "file_path = r'C:\\Users\\sarda\\Dropbox\\Research Reports (1)'\n",
    "\n",
    "# Get a list of all files in the directory\n",
    "file_list = os.listdir(file_path)\n",
    "\n",
    "# Create an empty DataFrame\n",
    "df = pd.DataFrame(columns=['File Name', 'Content'])\n",
    "\n",
    "# Iterate through each file in the directory\n",
    "for file_name in file_list:\n",
    "    full_path = os.path.join(file_path, file_name)\n",
    "\n",
    "    try:\n",
    "        with open(full_path, 'rb') as file:\n",
    "            result = chardet.detect(file.read())\n",
    "            encoding = result['encoding']\n",
    "\n",
    "        with open(full_path, 'r', encoding=encoding) as file:\n",
    "            content = file.read()\n",
    "\n",
    "        df = df.append({'File Name': file_name, 'Content': content}, ignore_index=True)\n",
    "\n",
    "    except UnicodeDecodeError as e:\n",
    "        print(f\"Error decoding file '{file_name}': {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading file '{file_name}': {e}\")\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cc1ccae",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "The specified directory 'C:\\Users\\sarda\\Dropbox\\Research Reports(1)' does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Check if the directory exists\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(file_path):\n\u001b[1;32m----> 8\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe specified directory \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m does not exist.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     10\u001b[0m file_list \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mlistdir(file_path)\n\u001b[0;32m     12\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFile Name\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mContent\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: The specified directory 'C:\\Users\\sarda\\Dropbox\\Research Reports(1)' does not exist."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "file_path = r'C:\\Users\\sarda\\Dropbox\\Research Reports(1)'\n",
    "\n",
    "# Check if the directory exists\n",
    "if not os.path.exists(file_path):\n",
    "    raise FileNotFoundError(f\"The specified directory '{file_path}' does not exist.\")\n",
    "\n",
    "file_list = os.listdir(file_path)\n",
    "\n",
    "df = pd.DataFrame(columns=['File Name', 'Content'])\n",
    "\n",
    "for file_name in file_list:\n",
    "    full_path = os.path.join(file_path, file_name)\n",
    "\n",
    "    try:\n",
    "        with open(full_path, 'r', encoding='utf-8') as file:\n",
    "            content = file.read()\n",
    "\n",
    "        df = df.append({'File Name': file_name, 'Content': content}, ignore_index=True)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading file '{file_name}': {e}\")\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "627a11a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                File Name\n",
      "0       'Astral PolyTech 120525 Networth Q4 FY12 resul...\n",
      "1       'Ethanol blending programme 120929 Care  still...\n",
      "2       'Wockhardt 120523 Networth  Buoyant profitabil...\n",
      "3       10 Annual Investor Conference 2012 120312 Icic...\n",
      "4       120601 Citi Takeaways from India Investor Conf...\n",
      "...                                                   ...\n",
      "119716  Zydus Wellness Limited 111227 Anand rathi Mana...\n",
      "119717  Zylog System 130328 Firstcall Q3 FY13 RU repor...\n",
      "119718            Zylog Systems 110303 Crisil q3fy11a.pdf\n",
      "119719  Zylog Systems 120326 jaypee management Meet Up...\n",
      "119720  Zylog Systems 120629 Crisil Strong revenue and...\n",
      "\n",
      "[119721 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "source_path = r'C:\\Users\\sarda\\Dropbox\\Research Reports (1)'\n",
    "\n",
    "# Check if the source directory exists\n",
    "if not os.path.exists(source_path):\n",
    "    raise FileNotFoundError(f\"The specified source directory '{source_path}' does not exist.\")\n",
    "\n",
    "# Get a list of PDF file names in the source directory\n",
    "pdf_file_names = [file_name for file_name in os.listdir(source_path) if file_name.lower().endswith('.pdf') and os.path.isfile(os.path.join(source_path, file_name))]\n",
    "\n",
    "# Create a DataFrame with the PDF file names\n",
    "df = pd.DataFrame({'File Name': pdf_file_names})\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b13d80d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                File Name\n",
      "23685   Chemicals 190618 IIFL - Conf.Key Updates- Navi...\n",
      "29431   Deepak Fertilisers 211215 IIFL Sec Initiating ...\n",
      "29432   Deepak Fertilisers 220201 IIFL Sec Q3 FY22 Res...\n",
      "29433   Deepak Fertilisers 220628 IIFL - NDR takeaways...\n",
      "29434   Deepak Fertilisers 220802 IIFL Sec Q1 FY23 Res...\n",
      "29435   Deepak Fertilisers 221212 IIFL Sec Co-Update -...\n",
      "29438   Deepak Fertilisers 230206 IIFL Sec Q3 FY23 res...\n",
      "29439   Deepak Fertilisers 230522 IIFL Sec Q4 FY23 Res...\n",
      "29441   Deepak Fertilisers 230731 IIFL Q1 FY24 result ...\n",
      "29454   Deepak Nitrite 170628 IIFL Mamgt Interaction u...\n",
      "29478   Deepak Nitrite 200819 IIFL Sec Q1 FY21 Result ...\n",
      "29480   Deepak Nitrite 210112 IIFL Top pick for 2021 -...\n",
      "29482   Deepak Nitrite 210218 IIFL Q3 FY21 result upda...\n",
      "29483   Deepak Nitrite 210301 IIFL Takeaway from IIFL ...\n",
      "29489   Deepak Nitrite 210806 IIFL Sec Q1 FY22 Result ...\n",
      "29495   Deepak Nitrite 211101 IIFL Sec Q2 FY22 Result ...\n",
      "29504   Deepak Nitrite 220811 IIFL Sec Q1 FY23 Result ...\n",
      "29508   Deepak Nitrite 221111 IIFL Sec Q2 FY23 result ...\n",
      "29510   Deepak Nitrite 230210 IIFL Sec Q3 FY23 Result ...\n",
      "29513   Deepak Nitrite 230217 IIFL Sec Q3 FY23 Result ...\n",
      "29519   Deepak Nitrite 230515 IIFL Sec Q4 FY23 Result ...\n",
      "29526   Deepak Nitrite 230809 IIFL Q1 FY24 result upda...\n",
      "49899   India Chemicals 171012 IIFL Q2 FY18E Expect im...\n",
      "49901   India Chemicals 200123 IIFL - Substitution Rea...\n",
      "109638  The Front Page 180516 IIFL Q4 FY18 result upda...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "source_path = r'C:\\Users\\sarda\\Dropbox\\Research Reports (1)'\n",
    "output_csv_path = r'C:\\Users\\sarda\\Dropbox\\Research Reports (1)\\pdf_file_names.csv'\n",
    "\n",
    "# Check if the source directory exists\n",
    "if not os.path.exists(source_path):\n",
    "    raise FileNotFoundError(f\"The specified source directory '{source_path}' does not exist.\")\n",
    "\n",
    "# Get a list of PDF file names in the source directory\n",
    "pdf_file_names = [file_name for file_name in os.listdir(source_path) if file_name.lower().endswith('.pdf') and os.path.isfile(os.path.join(source_path, file_name))]\n",
    "\n",
    "# Create a DataFrame with the PDF file names\n",
    "df = pd.DataFrame({'File Name': pdf_file_names})\n",
    "\n",
    "# Write the DataFrame to a CSV file\n",
    "df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "print(f\"PDF file names written to '{output_csv_path}'.\")\n",
    "\n",
    "\n",
    "# Filter the DataFrame for records containing 'IIFL' (case-insensitive)\n",
    "filtered_df = df[df['File Name'].str.contains('IIFL', case=False)]\n",
    "second_filtered_df = filtered_df[filtered_df['File Name'].str.contains('Deepak', case=False)]\n",
    "print(second_filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8ca402",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
